---
title: "Performance Comparison Example to Accompany Manuscript"
output: rmarkdown::html_vignette
bibliography: '`r system.file("REFERENCES.bib", package="fastfrechet")`'
vignette: >
  %\VignetteIndexEntry{Performance Comparison Example to Accompany Manuscript}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r knitr-options, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

```{r setup}
library(fastfrechet)
library(WRI)
library(frechet)
library(microbenchmark)
```

```{r load-code, include = FALSE}
s <- system.file("private", "GlobalObj4h.R", package = "fastfrechet")
if (file.exists(s)) source(s)
s <- system.file("private", "GloWassReg.R", package = "fastfrechet")
if (file.exists(s)) source(s)
s <- system.file("private", "IndivRidgeGloWassReg.R", package = "fastfrechet")
if (file.exists(s)) source(s)
s <- system.file("private", "lambdaGlobalcoordesc.R", package = "fastfrechet")
if (file.exists(s)) source(s)
```

# Purpose of Vignette

The R package `fastfrechet` implements fast and accurate algorithms for solving
Fréchet regression and variable selection for distributional responses. Existing
implementations for solving these problems are available in other R package and
non-package formats, but they are slow or provide inaccurate solutions in
settings with common constraints. The purpose of this vignette is to provide
performance comparisons (computation time, optimization accuracy) between
`fastfrechet` and these other implementations, using an example simulated data
set. For a general illustration of what Fréchet regression and variable
selection for distributional responses looks like, see the accompanying
`intro-fastfrechet` vignette.

Fréchet regression for distributional responses has previously been implemented
in the R packages `WRI` and `frechet`, as well as in Supplementary Material from
@tucker_variable_2023 (hereafter *Tucker materials*). Variable selection is a
newer method, and to the best of our knowledge is available only in non-package
format in the Tucker materials. As of writing this vignette (February 2025),
`WRI` and `frechet` are available for download from CRAN; and the Tucker
materials R function files are available for free download via the citation URL
included in the References section of this vignette. It is not our intent to be
primary maintainers or providers of these other methods.

The code chunks in this vignette allow replication of the computation time and
optimization accuracy comparisons. Computation times comparisons were made in a
single shot prior to vignette build time, using a 2021 Apple M1 Max chip, and
this vignette internally references those pre-saved results. For space reasons,
we also omit the code used to generate the figures herein.

## Example Data Set

In the Fréchet regression setting, we have classical covariate vectors stored in
matrix $\pmb{X} \in \mathbb{R}^{n\times p}$, and response objects obeying some
specified constraints. In this distributional response setting, these responses
are discretized quantile functions, vectors obeying a monotonicity constraint
and possible support constraints. They are stored row-wise in matrix
$\pmb{Y} \in \mathbb{R}^{n\times m}$, where $m$ is the density of an equidistant
grid in $(0, 1)$ on which each quantile function is evaluated.

The data we utilize for our comparisons are simulated covariate-dependent
zero-inflated negative binomial (`zinbinom`) distributions, which are
parameterized by a zero-inflation parameter $z$, size parameter $r$, and
probability parameter $\rho$. The `fastfrechet` function `generate_zinbinom_qf`
allows us to simulate $n$ such distributions, represented as quantile functions
evaluated on a shared $m$-grid in $(0, 1)$, dependent on the first 4 of
$p \geq 4$ covariates. Specifically, we generate covariates by
$$
\mathbf{x}_i \sim \mathcal{N}(\pmb{0}, \mathbf{I}_p), \qquad \forall i = 1, \dots, n.
$$
Then for each $i$, we generate a quantile function by first sampling the
distribution parameters via the following equations (dropping the $i$ subscript
for convenience)
$$
\begin{align*}
\mathrm{logit}(z) &\sim \mathcal{N}(\alpha_z + \beta_z \cdot x_4 \:, \: s_z^2), \\
\mathrm{log}(r) &\sim \mathcal{N}(\alpha_r + \beta_r \cdot (x_2 + x_3) \:, \: s_r^2), \\
\mathrm{logit}(\rho) &\sim \mathcal{N}(\alpha_{\rho} + \beta_{\rho} \cdot x_1 \:,\: s_{\rho}^2).
\end{align*}
$$
We use default parameters
$$
\begin{align*}
\begin{aligned}
\alpha_z &= \mathrm{logit}(0.2), &\qquad \beta_z &= 0.4, &\qquad s_z^2 &= 0.1^2,\\
\alpha_r &= \log(10), &\qquad \beta_r &= 0.2, &\qquad s_r^2 &= 0.15^2, \\
\alpha_{\rho} &= \mathrm{logit}(0.5) &\qquad \beta_{\rho} &= 0.2, &\qquad s_{\rho}^2 &= 0.15^2.
\end{aligned}
\end{align*}
$$
Finally, the quantile functions are generated by
$$
\mathbf{q}_{\mathbf{x}_i}( u \mid z_i, r_i, \rho_i) = F^{-1}_{\mathrm{nbinom}} \left( \frac{ u - z_i}{1 - z_i} \mid r_i, \rho_i  \right), \qquad u \in \left\{ \begin{matrix} \frac{1}{2m} & \frac{3}{2m} & \cdots & \frac{2m-1}{2m} \end{matrix} \right\},
$$
where $F^{-1}_{\mathrm{nbinom}}$ is effectuated by calling the `qnbinom`
function in R. The example data set we generate for this vignette has sample
size $n = 100$, covariate number $p = 10$, and quantile functions evaluated on
an equidistant $m = 100$ grid.

```{r generate-ZINB}
set.seed(31)
n <- 100 # number of quantile functions
p <- 10 # number of covariates
m <- 100 # (0, 1) quantile functions grid density

# Equidistant m-grid in (0, 1)
mseq <- seq(0.5 / m, 1 - 0.5 / m, length.out = m)

gendata <- generate_zinbinom_qf(n, p, m)
X <- gendata$X # (n x p) covariate matrix
Y <- gendata$Y # (n x m) quantile response matrix, stored row-wise
```

```{r figure1, include = FALSE}
# Copy the image from vignettes/ (or wherever it's generated)
png("zinb_examples.png", width = 6.5, height = 4, units = "in", res = 432)

par(mai = c(0.55, 0.6, 0.3, 0.08))
plot(
  x = c(), y = c(), xlim = c(-0.01, 1.01), ylim = c(0, max(Y)), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
matlines(mseq, t(Y), col = "black", lty = 1, lwd = 1.5)
axis(1, NULL, TRUE, FALSE, -1.1, cex.axis = 0.9)
axis(2, NULL, TRUE, FALSE, -0.9, las = 1, cex.axis = 0.9)
mtext("u", 1, 1.4, cex = 1.2)
mtext("Y(u)", 2, 1.5, cex = 1.2)
mtext(expression("Response Quantile Functions " * bold("Y")), 3, 0, cex = 1.3)

dev.off()
```

![](zinb_examples.png){width=100%}

# The Fréchet Regression Problem

The (global) Fréchet regression problem for distributional responses is a
weighted Fréchet mean problem, where inputs and outputs are discretized
distribution functions. The R package `fastfrechet` implements a fast and
numerically exact custom solver for Fréchet regression in this setting, inspired
by the dual active-set method of @arnstrom_dual_2022 (see the accompanying
`monotoneQP-fastfrechet` vignette). The function, `frechetreg_univar2wass`,
permits user-specified box constraints, and is natively amenable to the
weighting scheme used in the variable selection procedure described in the next
section. It also solves the regression problem in the case the covariate matrix
$\pmb{X}$ is low-rank.

Fréchet regression implementations are also available in the R packages `WRI`
(the `wass_regress` function) and `frechet` (the `GloDenReg` function), as well
as in the Tucker materials (the `GloWassReg` function). The implementation from
the `WRI` package can fit solutions when $\mathbf{X}$ is not full column rank,
however it does not take user-specified support constraints as input and does
not permit predictions on a separate set of covariate vectors (typically denoted
$\mathbf{Z} \in \mathbb{R}^{z \times p}$). It also requires the empirical
distribution objects be strictly monotone increasing, which excludes the
discretely supported distributions in our example; to include `WRI` in our
comparisons, we add a small monotone adjustment to the simulated distributions.
The implementations from `frechet` and the Tucker materials allow distribution
inputs that are not strictly increasing, specification of a separate prediction
matrix $\mathbf{Z}$, and user-specified box constraints. However, neither method
can solve the regression problem when $\mathbf{X}$ is not full column rank; the
former is relatively slow, even for small $m$; and the latter is not currently
available in an R package.

```{r frechet-times}
# WRI takes a data frame input:
X_df <- as.data.frame(X)

# Add small monotone adjustment to Y for WRI:
Y_adj <- Y + matrix(seq(0, 0.01, len = m), n, m, byrow = TRUE)
```

## Computation Time Comparison

We compare the four methods on time to solve the Fréchet regression problem for
the example data set using the R package `microbenchmark`, iterating the
solving procedure 15 times for each method. We can see the implementation from
`fastfrechet` is the fastest of the four methods, upward of $1000\times$ faster
than methods currently available in R packages.

```{r microbenchmark-frechetreg, eval = FALSE}
# Benchmark times over 5 iterations:
M1 <- microbenchmark(
  "WRI" = wass_regress(~., X_df, "quantile", Y_adj),
  "frechet" = GloDenReg(X, qin = Y, optns = list(lower = 0)),
  "Tucker" = GloWassReg(X, Y, X, lower = 0),
  "fastfrechet" = frechetreg_univar2wass(X, Y, lower = 0),
  times = 5,
  unit = "ms"
)

# Display times (milliseconds) rounded to 1 decimal:
M1$time <- round(M1$time / 1e6, 1) * 1e6
M1
```

```{r show-frechetreg-times, echo = FALSE}
# Load times:
s <- system.file("private", "microbenchmark_results.Rda", package = "fastfrechet")
if (file.exists(s)) load(s)

# Round frechetreg times:
M1_temp <- M1
M1_temp$time <- round(M1_temp$time / 1e6, 1) * 1e6

# Display rounded time summary:
M1_temp
```

## Optimization Accuracy Comparison

We compare the four methods on optimization accuracy for the Fréchet regression
on the example data set, highlighting two example curves by red and blue color.
We can see the implementation from `WRI` does not obey known box constraints
because the option to specify them is not available; the implementation from
`frechet` violates the lower box constraint despite its explicit inclusion as an
argument. The implementation from the Supplementary Material of
@tucker_variable_2023 and the implementation from `fastfrechet` both solve the
problem to numerical accuracy.
```{r fit-QFs, eval = FALSE}
# Fit quantile functions:
WRI_Q <- wass_regress(~., X_df, "quantile", Y_adj)$Qfit
frechet_Q <- GloDenReg(X, qin = Y, optns = list(lower = 0))$qout
Tucker_Q <- GloWassReg(X, Y, X, lower = 0)
fastfrechet_Q <- frechetreg_univar2wass(X, Y, lower = 0)$Qhat
```

```{r load-QFs, include = FALSE}
# Load quantile functions:
s <- system.file("private", "Q_results.Rda", package = "fastfrechet")
if (file.exists(s)) load(s)
```

```{r figure2, include = FALSE}
# Pick specific lines to plot:
pick <- c(54, 69)
plotcols <- c("#648FFF", "#785EF0", "#DC267F", "#FFB000", "black")

# Figure margin and size specifications:
# 0.4 + 4a + 4(0.06) = 6.5
a <- (6.5 - 0.32 - 0.45) / 4
mais <- cbind(
  c(0.35, 0.35, 0.35, 0.35),
  c(0.45, 0.04, 0.04, 0.04),
  c(0.2, 0.2, 0.2, 0.2),
  c(0.04, 0.04, 0.04, 0.08)
)
figs <- cbind(
  c(0, 0.4 + a + 0.04, 0.4 + 2 * (a + 0.04), 0.4 + 3 * (a + 0.04)) / 6.5,
  c(0.4 + a + 0.04, 0.4 + 2 * (a + 0.04), 0.4 + 3 * (a + 0.04), 6.5) / 6.5,
  c(0, 0, 0, 0),
  c(1, 1, 1, 1)
)

png("frechetreg_accuracy_comparison.png", width = 6.5, height = 2.2, units = "in", res = 432)

par(fig = figs[1, ], mai = mais[1, ], family = "Helvetica")
plot(
  x = c(), y = c(), xlim = c(-0.01, 1.01), ylim = c(-0.4, 0.4), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 0, lty = 2, col = "gray50")
matlines(mseq, t(WRI_Q), col = "black", lty = 1, lwd = 1.5)
matlines(mseq, t(WRI_Q[pick, ]), col = plotcols[c(1, 3)], lty = 1, lwd = 2)
axis(1, axTicks(1), c("0", "0.2", "0.4", "0.6", "0.8", 1), FALSE, -1.3, cex.axis = 0.55)
axis(2, NULL, TRUE, FALSE, -0.9, las = 1, cex.axis = 0.55)
mtext("u", 1, 0.7, cex = 0.8)
mtext(expression(widehat("Q") * "(u)"), 2, 1, cex = 0.8)
text(par("usr")[1] - 0.06, par("usr")[4] + 0.03,
  "WRI",
  pos = 4, xpd = TRUE, cex = 0.75, font = 2
)
text(par("usr")[1] + 0.17, par("usr")[4] + 0.0235,
  col = "gray40",
  "R PACKAGE", pos = 4, xpd = TRUE, cex = 0.45, font = 2
)
text(par("usr")[2] + 0.01, par("usr")[3] + 0.06,
  sprintf("%.4f sec", median(M1$time[M1$expr == "WRI"]) / 1e9),
  pos = 2, xpd = TRUE, cex = 0.55, font = 2
)
text(par("usr")[2] + 0.01, par("usr")[3] + 0.12, "median run time:",
  pos = 2, xpd = TRUE, cex = 0.5
)


par(fig = figs[2, ], mai = mais[2, ], new = TRUE)
plot(
  x = c(), y = c(), xlim = c(-0.01, 1.01), ylim = c(-0.4, 0.4), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 0, lty = 2, col = "gray50")
matlines(mseq, t(frechet_Q), col = "black", lty = 1, lwd = 1.5)
matlines(mseq, t(frechet_Q[pick, ]), col = plotcols[c(1, 3)], lty = 1, lwd = 2)
axis(1, axTicks(1), c("0", "0.2", "0.4", "0.6", "0.8", 1), FALSE, -1.3, cex.axis = 0.55)
mtext("u", 1, 0.7, cex = 0.8)
text(par("usr")[1] - 0.06, par("usr")[4] + 0.03,
  "frechet",
  pos = 4, xpd = TRUE, cex = 0.75, font = 2
)
text(par("usr")[1] + 0.32, par("usr")[4] + 0.0235,
  col = "gray40",
  "R PACKAGE", pos = 4, xpd = TRUE, cex = 0.45, font = 2
)
text(par("usr")[2] + 0.01, par("usr")[3] + 0.06,
  sprintf("%.4f sec", median(M1$time[M1$expr == "frechet"]) / 1e9),
  pos = 2, xpd = TRUE, cex = 0.55, font = 2
)
text(par("usr")[2] + 0.01, par("usr")[3] + 0.12, "median run time:",
  pos = 2, xpd = TRUE, cex = 0.5
)


par(fig = figs[3, ], mai = mais[3, ], new = TRUE)
plot(
  x = c(), y = c(), xlim = c(-0.01, 1.01), ylim = c(-0.4, 0.4), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 0, lty = 2, col = "gray50")
matlines(mseq, t(Tucker_Q), col = "black", lty = 1, lwd = 1.5)
matlines(mseq, t(Tucker_Q[pick, ]), col = plotcols[c(1, 3)], lty = 1, lwd = 2)
axis(1, axTicks(1), c("0", "0.2", "0.4", "0.6", "0.8", 1), FALSE, -1.3, cex.axis = 0.55)
mtext("u", 1, 0.7, cex = 0.8)
text(par("usr")[1] - 0.06, par("usr")[4] + 0.03,
  "Tucker",
  pos = 4, xpd = TRUE, cex = 0.75, font = 2
)
text(par("usr")[1] + 0.32, par("usr")[4] + 0.0235,
  col = "gray40",
  "PAPER SUPPLEMENT", pos = 4, xpd = TRUE, cex = 0.45, font = 2
)
text(par("usr")[2] + 0.01, par("usr")[3] + 0.06,
  sprintf("%.4f sec", median(M1$time[M1$expr == "Tucker"]) / 1e9),
  pos = 2, xpd = TRUE, cex = 0.55, font = 2
)
text(par("usr")[2] + 0.01, par("usr")[3] + 0.12, "median run time:",
  pos = 2, xpd = TRUE, cex = 0.5
)


par(fig = figs[4, ], mai = mais[4, ], new = TRUE)
plot(
  x = c(), y = c(), xlim = c(-0.01, 1.01), ylim = c(-0.4, 0.4), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 0, lty = 2, col = "gray50")
matlines(mseq, t(fastfrechet_Q), col = "black", lty = 1, lwd = 1.5)
matlines(mseq, t(fastfrechet_Q[pick, ]), col = plotcols[c(1, 3)], lty = 1, lwd = 2)
axis(1, axTicks(1), c("0", "0.2", "0.4", "0.6", "0.8", 1), FALSE, -1.3, cex.axis = 0.55)
mtext("u", 1, 0.7, cex = 0.8)
text(par("usr")[1] - 0.05, par("usr")[4] + 0.03,
  "fastfrechet",
  pos = 4, xpd = TRUE, cex = 0.75, font = 2
)
text(par("usr")[1] + 0.46, par("usr")[4] + 0.0235,
  col = "gray40",
  "R PACKAGE", pos = 4, xpd = TRUE, cex = 0.45, font = 2
)
text(par("usr")[2] + 0.01, par("usr")[3] + 0.06,
  sprintf("%.4f sec", median(M1$time[M1$expr == "fastfrechet"]) / 1e9),
  pos = 2, xpd = TRUE, cex = 0.55, font = 2
)
text(par("usr")[2] + 0.01, par("usr")[3] + 0.12, "median run time:",
  pos = 2, xpd = TRUE, cex = 0.5
)

dev.off()

new_width <- 3 * a + 0.52 + 0.04 + 0.52 + 0.08 + 0.52 + 0.08
# Figure margin and size specifications:
mais <- cbind(
  c(0.35, 0.35, 0.35),
  c(0.52, 0.52, 0.52),
  c(0.2, 0.2, 0.2),
  c(0.04, 0.08, 0.08)
)
figs <- cbind(
  c(0, 0.52 + a + 0.04, 0.52 + a + 0.04 + 0.52 + a + 0.08) / new_width,
  c(0.52 + a + 0.04, 0.52 + a + 0.04 + 0.52 + a + 0.08, new_width) / new_width,
  c(0, 0, 0),
  c(1, 1, 1)
)

# Calculate Yhat:
Xs <- cbind(1, scale(X))
Yhat <- Xs %*% solve(crossprod(Xs), crossprod(Xs, Y))

png("frechetreg_accuracy_comparison2.png", width = new_width, height = 2.2, units = "in", res = 432)

par(fig = figs[1, ], mai = mais[1, ], family = "Helvetica")
plot(
  x = c(), y = c(), xlim = c(-1, 101), ylim = c(-1e-14, 0.02), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 0, lty = 2, col = "gray50")
lines(rowSums((pmax(WRI_Q, 0) - Yhat)^2) - rowSums((fastfrechet_Q - Yhat)^2),
  col = "black", lty = 1, lwd = 1
)
axis(1, c(1, 100), c(1, 100), FALSE, -1.3, cex.axis = 0.55)
axis(2, axTicks(2), c("0", "0.005", "0.010", "0.015", "0.020"), FALSE, -0.9, las = 1, cex.axis = 0.55)
mtext("Sample (i)", 1, 0.7, cex = 0.8)
mtext(expression(f(widehat(Q))[WRI] - f(widehat(Q))[fastfrechet]),
  2, 1.5,
  cex = 0.8
)
text(par("usr")[1] - 6, par("usr")[4] + 0.03 / 0.8 * 0.02,
  "WRI",
  pos = 4, xpd = TRUE, cex = 0.75, font = 2
)
text(par("usr")[1] + 17, par("usr")[4] + 0.0235 / 0.8 * 0.02,
  col = "gray40",
  "R PACKAGE", pos = 4, xpd = TRUE, cex = 0.45, font = 2
)

par(fig = figs[2, ], mai = mais[2, ], new = TRUE)
plot(
  x = c(), y = c(), xlim = c(-1, 101), ylim = c(-1e-14, 0.02), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 0, lty = 2, col = "gray50")
lines(rowSums((pmax(frechet_Q, 0) - Yhat)^2) - rowSums((fastfrechet_Q - Yhat)^2),
  col = "black", lty = 1, lwd = 1
)
axis(1, c(1, 100), c(1, 100), FALSE, -1.3, cex.axis = 0.55)
axis(2, axTicks(2), c("0", "0.005", "0.010", "0.015", "0.020"), FALSE, -0.9, las = 1, cex.axis = 0.55)
mtext("Sample (i)", 1, 0.7, cex = 0.8)
mtext(expression(f(widehat(Q))[frechet] - f(widehat(Q))[fastfrechet]),
  2, 1.5,
  cex = 0.8
)
text(par("usr")[1] - 6, par("usr")[4] + 0.03 / 0.8 * 0.02,
  "frechet",
  pos = 4, xpd = TRUE, cex = 0.75, font = 2
)
text(par("usr")[1] + 32, par("usr")[4] + 0.0235 / 0.8 * 0.02,
  col = "gray40",
  "R PACKAGE", pos = 4, xpd = TRUE, cex = 0.45, font = 2
)

par(fig = figs[3, ], mai = mais[3, ], new = TRUE)
plot(
  x = c(), y = c(), xlim = c(-1, 101), ylim = c(0, 2e-13), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 0, lty = 2, col = "gray50")
lines(rowSums((Tucker_Q - Yhat)^2) - rowSums((fastfrechet_Q - Yhat)^2),
  col = "black", lty = 1, lwd = 1
)
axis(1, c(1, 100), c(1, 100), FALSE, -1.3, cex.axis = 0.55)
axis(2, axTicks(2), c(
  "0",
  expression("0.5" * scriptstyle("E") * -"13"),
  expression("1.0" * scriptstyle("E") * -"13"),
  expression("1.5" * scriptstyle("E") * -"13"),
  expression("2.0" * scriptstyle("E") * -"13")
), FALSE, -0.9, las = 1, cex.axis = 0.5)
mtext("Sample (i)", 1, 0.7, cex = 0.8)
mtext(expression(f(widehat(Q))[Tucker] - f(widehat(Q))[fastfrechet]),
  2, 1.75,
  cex = 0.8
)
text(par("usr")[1] - 6, par("usr")[4] + 0.03 / 0.8 * 2e-13,
  "Tucker",
  pos = 4, xpd = TRUE, cex = 0.75, font = 2
)
text(par("usr")[1] + 32, par("usr")[4] + 0.0235 / 0.8 * 2e-13,
  col = "gray40",
  "PAPER SUPPLEMENT", pos = 4, xpd = TRUE, cex = 0.45, font = 2
)

dev.off()
```

![](frechetreg_accuracy_comparison.png){width=100%}

Depsite `WRI` and `frechet` not adequately handling box constraints natively,
constraints like $\widehat{Q} \geq \texttt{lower} = 0$ can possibly be applied
*post hoc*. Nonetheless, even doing so, the resulting solutions do not minimize
the Fréchet regression objective function as well as the solutions from the
`Tucker` materials and, `fastfrechet`.
```{r manually_box_solutions, eval = FALSE}
# Fit quantile functions:
WRI_Q <- pmax(WRI_Q, 0)
frechet_Q <- pmax(frechet_Q, 0)
```

![](frechetreg_accuracy_comparison2.png){width=100%}

# The Variable Selection Problem

The variable selection problem for Fréchet regression comprises finding an
optimal weight vector $\widehat{\pmb{\lambda}} \in \mathbb{R}^p$ that satisfies
a $\tau$-simplex constraint, for fixed hyperparameter $\tau > 0$. Solving the
variable selection problem involves iteratively solving a
$\pmb{\lambda}$-weighted version of the associated Fréchet regression problem.
In the 2-Wasserstein space setting, the optimal $\widehat{\pmb{\lambda}}$
essentially minimizes an $L^2$ norm between these weighted Fréchet means and the
raw data `Y`. (See the accompanying vignette `intro-fastfrechet`, and
@coulter_fast_2024 for a more detailed exposition.)

The R package `fastfrechet` implements variable selection for Fréchet regression
in 2-Wasserstein space, implementing the second-order geodesic descent algorithm
developed by @coulter_fast_2024. The function, `FRiSO_univar2wass`, includes two
new modifications. First, the implementation utilizes the custom dual active-set
method discussed in the previous subsection to solve the iterative
$\pmb{\lambda}$-weighted Fréchet regression problem. For each step, as weight
vector $\pmb{\lambda}^t \rightarrow \pmb{\lambda}^{t+1}$ is updated, the
previously estimated Lagrangian for the Fréchet regression solution is used as a
warm start for the subsequent iterate. Second, the implementation includes an
option for the user to specify an impulse parameter, to utilize momentum-based
geodesic descent.

Existing implementation of variable selection for Fréchet regression is
available in the Supplementary Material of @tucker_variable_2023 (the function
`IndivRidgeGloWassReg`, which solves the $\pmb{\lambda}$-weighted Fréchet
regression problem, and the function `lambdaGlobalcoordesc`, which is the
variable selection workhorse). The method is a particular implementation of an
algorithm which can be generally applied to Fréchet regression in other settings
besides 2-Wasserstein space. However, it is slow and does not natively handle
the low-rank setting, and is not currently available in an R package.

## Computation Time Comparison

We compare the two methods to solve the variable selection problem over a range
of hyperparameter values $\tau \in \{0.5, 1.0, \cdots, 10.0\}$, iterating the
solving procedure 15 times for each method. Since the implementation available
from @tucker_variable_2023 does not natively take multiple $\tau$ values as
input, we wrote a short wrapper function (given below) which loops over the
$\tau$ values, and each step uses the previously fitted
$\widehat{\pmb{\lambda}}$ vector as a warm start for the subsequent $\tau$
iterate.

```{r Tucker-function}
# Wrapper function for Tucker et al. (2023) code:
FRiSO_Tucker <- function(X, Y, lower, upper, tauseq) {
  p <- ncol(X)
  Lambda <- matrix(NA, nrow = p, ncol = length(tauseq))
  L <- rep(tauseq[1] / p, p)
  for (t in 1:length(tauseq)) {
    L <- lambdaGlobalcoordesc(X, Y, tauseq[t], L, lower, upper)$lambda
    Lambda[, t] <- L
  }
  Lambda
}
```

We standardize the comparison to `fastfrechet` in two ways. First, as
the implementation from `fastfrechet` centers and scales $\pmb{X}$ to remove the
effect of unit choice on variable selection, we similarly center and scale
$\pmb{X}$ prior to using the implementation from @tucker_variable_2023. Second,
as the two algorithms are forms of iterative descent methods, comparison on
computation time should be made for exit conditions that attain solutions of
approximately equal quality. To this end, we use the method from
@tucker_variable_2023 "as is", and hand select `fastfrechet` error tolerance
of $\varepsilon = 0.014$. This gives `fastfrechet` solutions that minimize the
objective function over the $\tau$ range approximately as well as the solutions
from the other method. For completeness, we also run the `fastfrechet` method on
more stringent error tolerances, progressively halving the error tolerance
parameter.

```{r scale-tauseq-eseq}
# Centering and scaling X
X0 <- (scale(X) * sqrt(n / (n - 1)))[, ]

# Defining tau range, and error tolerances:
tauseq <- seq(0.5, 10, by = 0.5)
eseq <- 0.014 / c(1, 2, 4, 8)
```

The implementation from `fastfrechet` is upward of 20,000$\times$ faster than
the implementation from @tucker_variable_2023, to attain a solution of
approximately equal quality. Decreasing the `fastfrechet` error tolerance
parameter slightly increases computation time, but still maintains sizable speed
benefits.

```{r FRiSO-times, eval = FALSE}
# Benchmark times over 5 iterations:
M2 <- microbenchmark(
  "Tucker" = FRiSO_Tucker(X0, Y, 0, 1e6, tauseq),
  "fastfrechet_e" = FRiSO_univar2wass(X, Y, 0, Inf, tauseq, eps = eseq[1]),
  "fastfrechet_e/2" = FRiSO_univar2wass(X, Y, 0, Inf, tauseq, eps = eseq[2]),
  "fastfrechet_e/4" = FRiSO_univar2wass(X, Y, 0, Inf, tauseq, eps = eseq[3]),
  "fastfrechet_e/8" = FRiSO_univar2wass(X, Y, 0, Inf, tauseq, eps = eseq[4]),
  times = 5,
  unit = "ms"
)

# Display times (milliseconds) rounded to 1 decimal:
M2$time <- round(M2$time / 1e6, 1) * 1e6
M2
```

```{r show-FRiSO-times, echo = FALSE}
# Round FRiSO times:
M2_temp <- M2
M2_temp$time <- round(M2_temp$time / 1e6, 1) * 1e6

# Display rounded time summary:
M2_temp
```

## Optimization Accuracy Comparison

We compare the two methods on optimization accuracy for the variable selection
problem on the example data set, using relative objective function ratios. The
optimal $\widehat{\pmb{\lambda}}$ minimizes an objective function (see the
accompanying vignette `intro-fastfrechet`, and @tucker_variable_2023 and
@coulter_fast_2024), so relative optimization accuracy can be measured by which
solution minimizes the objective function better. For the `fastfrechet` error
tolerance of $\varepsilon = 0.014$, both methods attain comparably accurate
solutions. As expected, the `fastfrechet` solutions become more accurate as the
error tolerance parameter decreases, with only modest increases in computation
time.

```{r obtain-FRiSO-lambdas, eval = FALSE}
# Set sequence of error tolerances:
eseq <- 0.014 / c(1, 2, 4, 8)

# Calculate lambdas with fastfrechet implementation:
L_fastfrechet <- sapply(eseq, function(e) {
  FRiSO_univar2wass(X, Y, 0, Inf, tauseq, eps = e)
}, simplify = "array")

# Calculate lambdas with Tucker et al. (2023) implementation:
L_Tucker <- FRiSO_Tucker(X0, Y, 0, 1000, tauseq)
```

```{r load-FRiSO-lambdas, include = FALSE}
# Load lambda path results:
s <- system.file("private", "L_results.Rda", package = "fastfrechet")
if (file.exists(s)) load(s)
```

```{r figure3, include = FALSE}
# Calculate objective function values for fastfrechet implementation:
f_fastfrechet <- matrix(apply(expand.grid(tauseq, eseq), 1, function(x) {
  t <- which(tauseq == x[1])
  e <- which(eseq == x[2])
  Q <- frechetreg_univar2wass(X, Y, lambda = L_fastfrechet[, t, e], lower = 0)$Qhat
  mean((Y - Q)^2)
}), ncol = 4)

# Calculate objective function values for Tucker et al. (2023) implementation:
f_Tucker <- sapply(1:length(tauseq), function(t) {
  Q <- frechetreg_univar2wass(X, Y, lambda = L_Tucker[, t], lower = 0)$Qhat
  mean((Y - Q)^2)
})

# 0.45 + 0.75 + 3a + 2(0.08) = 6.5
a <- (6.5 - 0.16 - 0.4 - 0.55) / 3
mais <- cbind(
  c(0.35, 0.35, 0.35),
  c(0.4, 0.04, 0.55),
  c(0.2, 0.2, 0.2),
  c(0.04, 0, 0.08)
)
figs <- cbind(
  c(0, 0.4 + a + 0.04, 0.4 + a + 0.08 + a) / 6.5,
  c(0.4 + a + 0.04, 0.4 + a + 0.08 + a, 6.5) / 6.5,
  c(0, 0, 0),
  c(1, 1, 1)
)
# Save graph:
png("friso_accuracy_comparison.png", width = 6.5, height = a + 0.35 + 0.2, units = "in", res = 432)

par(mai = mais[1, ], fig = figs[1, ], family = "Helvetica")
plot(
  x = c(), y = c(), xlim = c(-0.1, 10.1), ylim = c(0, 4), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 0, lty = 2, col = "gray50")
matlines(tauseq, t(L_Tucker), col = "black", lty = 1)
axis(1, NULL, TRUE, FALSE, -1.3, cex.axis = 0.55)
axis(2, NULL, TRUE, FALSE, -0.9, las = 1, cex.axis = 0.55)
mtext(expression(tau), 1, 0.7, cex = 0.8)
mtext(expression(widehat(bold(lambda)) * "(" * tau * ")"), 2, 0.65, cex = 0.8)
text(par("usr")[1] - 0.6, par("usr")[4] + 0.15,
  "Tucker",
  pos = 4, xpd = TRUE, cex = 0.75, font = 2
)
text(par("usr")[1] + 2.3, par("usr")[4] + 0.1175,
  col = "gray40",
  "PAPER SUPPLEMENT", pos = 4, xpd = TRUE, cex = 0.45, font = 2
)
text(par("usr")[1] + 0.1, par("usr")[4] - 0.35, "median run time:",
  pos = 4, xpd = TRUE, cex = 0.5
)
text(par("usr")[1] + 0.1, par("usr")[4] - 0.6,
  sprintf("%.4f sec", median(M2$time[M2$expr == "Tucker"]) / 1e9),
  pos = 4, xpd = TRUE, cex = 0.55, font = 2
)



par(mai = mais[2, ], fig = figs[2, ], new = TRUE)
plot(
  x = c(), y = c(), xlim = c(-0.1, 10.1), ylim = c(0, 4), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 0, lty = 2, col = "gray50")
matlines(tauseq, t(L_fastfrechet[, , 1]), col = "black", lty = 1)
axis(1, NULL, TRUE, FALSE, -1.3, cex.axis = 0.55)
mtext(expression(tau), 1, 0.7, cex = 0.8)
text(par("usr")[1] - 0.6, par("usr")[4] + 0.15,
  "fastfrechet",
  pos = 4, xpd = TRUE, cex = 0.75, font = 2
)
text(par("usr")[1] + 3.7, par("usr")[4] + 0.1175,
  col = "gray40",
  "R PACKAGE", pos = 4, xpd = TRUE, cex = 0.45, font = 2
)
text(par("usr")[1] + 0.1, par("usr")[4] - 0.35,
  expression("median run time (" * epsilon * " = 0.014):"),
  pos = 4, xpd = TRUE, cex = 0.5
)
text(par("usr")[1] + 0.1, par("usr")[4] - 0.6,
  sprintf("%.4f sec", median(M2$time[M2$expr == "fastfrechet_e"]) / 1e9),
  pos = 4, xpd = TRUE, cex = 0.55, font = 2
)


par(mai = mais[3, ], fig = figs[3, ], new = TRUE)
plot(
  x = c(), y = c(), xlim = c(-0.1, 10.1), ylim = c(0.9999, 1.0001), axes = FALSE,
  xlab = "", ylab = ""
)
polygon(
  x = par("usr")[c(1, 2, 2, 1)], y = par("usr")[c(3, 3, 4, 4)],
  col = "gray93", border = NA
)
abline(h = axTicks(2), v = axTicks(1), col = "white")
abline(h = 1, lty = 2, col = "gray50")
matlines(tauseq, f_fastfrechet / f_Tucker,
  type = "o", lty = 1,
  col = c("black", "#648FFF", "#FFB000", "#DC267F"),
  lwd = 1, pch = 15:18, cex = c(0.5, 0.5, 0.5, 0.7)
)
axis(1, NULL, TRUE, FALSE, -1.3, cex.axis = 0.55)
axis(2, c(0.9999, 1, 1.0001),
  c(expression("1 \U2013 10"^-4), expression("1.0"), expression("1 + 10"^-4)), FALSE, -0.9,
  las = 1, cex.axis = 0.55
)
mtext(expression(tau), 1, 0.7, cex = 0.8)
mtext(expression("f(" * bold(widehat(lambda)) * ")"["fastfrechet"] * " / f(" * bold(widehat(lambda)) * ")"[Tucker]),
  2, 1.3,
  las = 0, cex = 0.8
)
legend("topleft",
  col = c("black", "#648FFF", "#FFB000", "#DC267F"),
  pch = 15:18, lwd = 1, bty = "n", cex = 0.52, pt.cex = c(0.5, 0.5, 0.5, 0.7),
  legend = sapply(1:4, function(e) bquote(epsilon * " = " * .(eseq[e]) * " (" * .(round(median(M2$time[M2$expr == levels(M2$expr)[e + 1]]) / 1e6, 1)) * " ms)"))
)

dev.off()
```

![](friso_accuracy_comparison.png){width=100%}
